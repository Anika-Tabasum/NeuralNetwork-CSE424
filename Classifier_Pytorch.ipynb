{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a11bdc7-1d35-46c8-b4a0-d131ec648ddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA is available. Device count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\__init__.py:764\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m    763\u001b[0m __name, __obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    766\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(__name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Device count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\" - Memory allocated: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\" - Memory cached: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19a100-1133-4293-bb4b-990d7ce56664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "import gzip\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c2341-0756-4704-82cf-60396ac23240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, data_type='train', transform=None, target_transform=None) -> None:\n",
    "        \"\"\"\n",
    "        Custom dataset class for MNIST data.\n",
    "\n",
    "        :param root: Root directory where MNIST files are stored.\n",
    "        :param data_type: 'train' or 't10k' to load the corresponding dataset.\n",
    "        :param transform: Transformation to apply to the images.\n",
    "        :param target_transform: Transformation to apply to the labels.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data = None\n",
    "        self.targets = None\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Load the MNIST dataset from gzip files using PyTorch utilities.\"\"\"\n",
    "        # Construct the paths for labels and images\n",
    "        labels_path = os.path.join(self.root, f'{self.data_type}-labels-idx1-ubyte.gz')\n",
    "        images_path = os.path.join(self.root, f'{self.data_type}-images-idx3-ubyte.gz')\n",
    "\n",
    "        # Load the labels\n",
    "        with gzip.open(labels_path, 'rb') as lbpath:\n",
    "            labels = torch.tensor(list(lbpath.read()[8:]), dtype=torch.long)\n",
    "            self.targets = labels\n",
    "\n",
    "        # Load the images and reshape them to (num_samples, 28, 28)\n",
    "        with gzip.open(images_path, 'rb') as imgpath:\n",
    "            images = torch.tensor(list(imgpath.read()[16:]), dtype=torch.uint8)\n",
    "            self.data = images.view(-1, 28, 28)  # Reshape to (num_samples, 28, 28)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Get the item at the given index.\n",
    "        :param index: The index of the item.\n",
    "        :return: The transformed image and label at the index.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the total number of items in the dataset.\"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ec89c-c2a7-46b6-800a-176f476b15b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/shaha/Desktop/CSE424\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72da63c-b8f1-440d-8aa0-b78a388d7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(0).float()),  # Add the channel dimension (1, 28, 28) and convert to float32\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Lambda(lambda x: x.reshape(-1)),  # Flatten the image into a 1D tensor\n",
    "])\n",
    "\n",
    "\n",
    "# you can transform the target too if you want (e.g. one hot encode)\n",
    "target_transform = transforms.Lambda(\n",
    "    lambda y: y.clone().detach().long()  # Detach and convert to long type\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70b87e-80a4-434f-989a-8a1b6af7baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/c/Users/shaha/Desktop/CSE424\"\n",
    "\n",
    "dataset = MNISTDataset(data_path, transform=transform,\n",
    "                  target_transform=target_transform)\n",
    "\n",
    "# dataset = ImageFolder(data_path, transform=transform,\n",
    "#                      target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d252038-fd87-424c-b893-f26873689c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size = 60000\n",
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 72.94035339355469 \n",
      "Pixel Values Std: 90.02118682861328\n",
      "Scaled Mean Pixel Value 0.28604060411453247 \n",
      "Scaled Pixel Values Std: 0.35302427411079407\n"
     ]
    }
   ],
   "source": [
    "print(f'Size = {len(dataset)}')\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(dataset.data.min(), dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(dataset.data.float().mean(), dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(dataset.data.float().mean() / 255, dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead36978-d024-4c9e-bf83-bff52e7af6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 48000\n",
      "Validation size: 12000\n"
     ]
    }
   ],
   "source": [
    "#spliting \n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size  # Ensure the total matches the dataset size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44ee38-693e-4c8e-bf2a-9a685fa00d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    \"\"\"The linear classifier model\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, num_classes: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MLP model\n",
    "\n",
    "        :param input_size: The input size\n",
    "        :type input_size: int\n",
    "        :param num_classes: The number of classes\n",
    "        :type num_classes: int\n",
    "        \"\"\"\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, num_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    # This part is optional (Weight initialization)\n",
    "    #     self.init_weights()\n",
    "\n",
    "    # def init_weights(self):\n",
    "    #     for m in self.modules():\n",
    "    #         if type(m) == torch.nn.Linear:\n",
    "    #             torch.nn.init.xavier_uniform_(m.weight)\n",
    "    #             m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "\n",
    "        :param x: The input tensor\n",
    "        :type x: torch.Tensor\n",
    "\n",
    "        :return: The output tensor\n",
    "        :rtype: torch.Tensor\n",
    "        \"\"\"\n",
    "        z = self.fc1(x)\n",
    "        out = self.softmax(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2de728-21d3-46f7-929e-12a5129d5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment parameters\n",
    "input_dim = 28 * 28\n",
    "num_classes = 10\n",
    "batch_sizes = [2048, 1024, 512]\n",
    "learning_rates = [0.001, 0.0001]\n",
    "num_epochs = 100\n",
    "\n",
    "# Track the best configuration\n",
    "best_macro_f1 = 0\n",
    "best_batch_size = None\n",
    "best_learning_rate = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae483d6-4733-4819-987e-8b17ce8e0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Ensure you're importing tqdm\n",
    "\n",
    "# Iterate through each combination of batch size and learning rate\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}\")\n",
    "        \n",
    "        # Create DataLoaders with the current batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        model = LinearClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # Track training and validation losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_f1_scores = []\n",
    "\n",
    "        # Training loop with tqdm progress bar\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set model to training mode\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # Wrap the train_loader with tqdm to show progress\n",
    "            for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Training)\", leave=False):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_train_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = running_train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "\n",
    "            # Validation phase with tqdm progress bar\n",
    "            model.eval()  # Set model to evaluation mode\n",
    "            running_val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            with torch.no_grad():\n",
    "                # Wrap the val_loader with tqdm to show progress\n",
    "                for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} (Validation)\", leave=False):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_val_loss += loss.item()\n",
    "                    _, preds = torch.max(outputs, 1)  # Get predicted class labels\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            avg_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            # Calculate F1 score for validation\n",
    "            val_macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "            val_f1_scores.append(val_macro_f1)\n",
    "\n",
    "        # Get the highest F1 score from this experiment\n",
    "        max_val_f1 = max(val_f1_scores)\n",
    "        if max_val_f1 > best_macro_f1:\n",
    "            best_macro_f1 = max_val_f1\n",
    "            best_batch_size = batch_size\n",
    "            best_learning_rate = lr\n",
    "\n",
    "        print(f\"Finished Training with Batch Size: {batch_size}, Learning Rate: {lr}\")\n",
    "        print(f\"Best Validation Macro F1 Score: {max_val_f1:.4f}\\n\")\n",
    "\n",
    "        # Plot training and validation loss\n",
    "        plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "        plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='red')\n",
    "        plt.title(f\"Batch Size: {batch_size}, Learning Rate: {lr}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# After all experiments, print the best configuration\n",
    "print(f\"Best Configuration - Batch Size: {best_batch_size}, Learning Rate: {best_learning_rate}\")\n",
    "print(f\"Best Validation Macro F1 Score: {best_macro_f1:.4f}\")\n",
    "\n",
    "# Retrain with the best configuration using the entire training dataset\n",
    "train_loader = DataLoader(train_dataset_full, batch_size=best_batch_size, shuffle=True)\n",
    "model = LinearClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "# Train for 100 epochs\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/100 (Final Training)\"):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "# Test the model and calculate F1 score on the test set\n",
    "test_images_tensor = torch.tensor(test_images).view(-1, 28 * 28)\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_batch_size)\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(\"F1 Score on Test Set:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
